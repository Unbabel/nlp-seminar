# Welcome to Unbabel's AI Reading Group Page

We have a weekly gathering to discuss recent papers in NLP and AI. This are very informal and relaxed reading meetings, so slides are not required although presenters usually make them. Below is the past schedule of presented papers.

## Schedule

### <span id="anchor"></span>2020-05-25

@Ricardo

Paper: [\[2004.13637\] Recipes for building an open-domain
chatbot](https://arxiv.org/abs/2004.13637)

### <span id="anchor-1"></span>2020-05-18

@Daan and @Fabio

Paper: [\[1905.00076\] Ensemble Distribution
Distillation](https://arxiv.org/abs/1905.00076) and [\[2002.11531\] A
general framework for ensemble distribution
distillation](https://arxiv.org/abs/2002.11531)

Slides: [RG - Ensemble Distribution
Distillation](https://docs.google.com/presentation/d/1fEJgP-liWBpPd3HMNImt9eUNXpyJCatkmcH-jAfjycM/edit?usp=sharing)

### <span id="anchor-2"></span>2020-05-11

@Patrick

Paper: [\[2004.03061\] Information-Theoretic Probing for Linguistic
Structure](https://arxiv.org/abs/2004.03061)

Slides: [Information-Theoretic Probing for Linguistic
Structure](https://docs.google.com/presentation/d/1v4dFsjS78yUjytuCmQPnqYFKnSsbl5W8AL3NtIKBtjU/edit?usp=sharing)

### <span id="anchor-3"></span>2020-05-04

@Daan

Paper: [\[2003.12298\] Information-Theoretic Probing with Minimum
Description Length](https://arxiv.org/abs/2003.12298)

Blog: [Information-Theoretic Probing with
MDL](https://lena-voita.github.io/posts/mdl_probes.html)

Slides: [Information-Theoretic
Probing](https://docs.google.com/presentation/d/1lDDK2t-QWDz7UjBr0M9AX1p6y7CchHLl6ihgDB70Hik/edit?usp=sharing)

### <span id="anchor-4"></span>2020-03-30

Pedro Lobato

Paper: [ELECTRA: Pre-Training Text Encoders as Discriminators rather
than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)

Slides: [Google
Slides](https://docs.google.com/presentation/d/1I1MsGSgIFx_bDJ808QmRosxpliCJmApKhBSE_et2zEw/edit?usp=sharing)

### <span id="anchor-5"></span>2020-03-09

@Katya

Paper: [Mixout: Effective Regularization to Finetune Large-scale
Pretrained Language Models](https://arxiv.org/abs/1909.11299) and
[Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework
for Neural Language Generation
Models](https://arxiv.org/abs/1910.07117)

Slides: [mixout and
mix-review](https://docs.google.com/presentation/d/1BDLiiJcu3116iiJXdgjM6w9VuuCn5d59dF5rKtl1LYU/edit?usp=sharing)

### 2020-02-17

@Daan

Paper: [Torch-Struct: Deep Structured Prediction
Library](https://arxiv.org/pdf/2002.00876.pdf)

Slides:
[Torch-Struct](https://docs.google.com/presentation/d/1mOXAodxBszFMm0AlXwQVIvf-OWRoGgaJ28dWh4wGcZo/edit?usp=sharing)

### 2020-01-27

@Nuno Miguel G and Pedro Lobato

Paper: [Reformer: The Efficient
Transformer](https://arxiv.org/abs/2001.04451)
([PDF](https://arxiv.org/pdf/2001.04451.pdf))

### 2020-01-12

@Amin and @António

Paper: 

### 2020-01-05

@Ekaterina

Paper: [Optimizing data usage via differentiable
rewards](https://arxiv.org/abs/1911.10088)

Slides: [“Optimizing data usage via differentiable rewards” by Xinyi
Wang et
al.](https://docs.google.com/presentation/d/1nb6VPWbu__hzitrseOwNXFkFEakhqjv4Ap8XerdmfgY/edit?usp=sharing)

  

### 2019-12-30

@Catarina F

Paper: [Gmail Smart Compose: Real-Time Assisted
Writing](https://arxiv.org/pdf/1906.00080.pdf)

### 2019-12-16

@Fabio and @Amin

Paper: [Neural Machine Translation with Soft
Prototype](https://papers.nips.cc/paper/8861-neural-machine-translation-with-soft-prototype.pdf)

### 2019-12-09

@Miguel and @Nuno Miguel G

Paper: [Improving Conditioning in Context-Aware Sequence to Sequence
Models](https://arxiv.org/pdf/1911.09728.pdf)

### 2019-12-02

@Ekaterina and @Fabio

Paper: [On NMT Search Errors and Model Errors: Cat Got Your
Tongue?](https://www.aclweb.org/anthology/D19-1331/)

### 2019-11-25

@António

Paper: [Exploring the Limits of Transfer Learning with a Unified
Text-to-Text Transformer](https://arxiv.org/pdf/1910.10683.pdf)

### 2019-11-18

Pedro Lobato

Paper: [Mask-Predict: Parallel Decoding of Conditional Masked Language
Models](https://arxiv.org/pdf/1904.09324.pdf)

### 2019-11-11

@Fabio

Paper: [Improving Back-Translation with Uncertainty-based Confidence
Estimation](https://arxiv.org/abs/1909.00157)

### 2019-11-04

@Sérgio

Paper: [CORRECTION OF AUTOMATIC SPEECH RECOGNITION WITH TRANSFORMER
SEQUENCE-TO-SEQUENCE MODEL](https://arxiv.org/pdf/1910.10697.pdf)

### 2019-10-28

@Ricardo

Paper: [75 Languages, 1 Model: Parsing Universal Dependencies
Universally](https://arxiv.org/abs/1904.02099)

### 2019-10-21

Rafaela Saraiva

Paper: T[raining Neural Response Selection for Task-Oriented Dialogue
Systems ](https://arxiv.org/abs/1906.01543)

### 2019-10-14

Pedro Lobato

Paper: [TinyBERT](https://arxiv.org/abs/1909.10351)

### 2019-09-09

Pedro Lobato

Paper: [Large Memory Layers with Product
Keys](https://arxiv.org/abs/1907.05242)

### 2019-08-26

Invited speaker: Patrick Fernandes

Paper: [Structured Neural
Summarization](https://openreview.net/pdf?id=H1ersoRqtm) (ICLR 2019)

### 2019-08-19

@Ricardo

Paper: [Do Neural Dialog Systems Use Conversation History Effectively?
An Empirical Study](https://arxiv.org/abs/1906.01603) (And if we have
time: [Pretraining Methods for Dialog Context Representation
Learning](https://arxiv.org/abs/1906.00414))

### 2019-08-12

ACL compilation and digest.

### 2019-08-05

@Daan

Title: Neural language models with latent syntax

Description: In this talk I will present my thesis work at the
University of Amsterdam under supervision of Wilker Aziz. In the work I
investigate semi-supervised and unsupervised learning of the recurrent
neural network grammar (RNNG) (Dyer et al. 2016). I will also briefly
describe concurrent work by Kim et al. (2019) who (unbeknownst to me)
worked on an almost identical approach.

Slides:
[https://github.com/daandouwe/thesis/blob/master/doc/presentation-unbabel.pdf](https://github.com/daandouwe/thesis/blob/master/doc/presentation-unbabel.pdf)

Links:

  - Thesis
    [https://msclogic.illc.uva.nl/theses/archive/publication/4811/Neural-language-models-with-latent-syntax](https://msclogic.illc.uva.nl/theses/archive/publication/4811/Neural-language-models-with-latent-syntax)
    and code
    [https://github.com/daandouwe/thesis](https://github.com/daandouwe/thesis)
  - Original RNNG (Dyer et al. 2016)
    [https://www.aclweb.org/anthology/N16-1024](https://www.aclweb.org/anthology/N16-1024)
  - Unsupervised RNNG (Kim et al. 2019)
    [https://www.aclweb.org/anthology/N19-1114](https://www.aclweb.org/anthology/N19-1114)

### 2019-07-22

Invited speaker: Daniel Loureiro

He’s going to talk about his accepted paper at ACL:

“Language Modelling Makes Sense: Propagating Representations through
WordNet for Full-Coverage Word Sense Disambiguation”

### 2019-07-08

Antonio Gois

Resuming XLnet and related papers

Slides: [non-sequential
overview](https://docs.google.com/presentation/d/16-dtI3Xjnb49ZB91GcP22yrfUKB8zSihE31PMWsANPs/edit?usp=sharing)

### 2019-07-01

@Tsvetomila and @Marcos

Paper: [\[1906.08237\] XLNet: Generalized Autoregressive Pretraining
for Language Understanding](https://arxiv.org/abs/1906.08237)

Slides:
[XLNet](https://docs.google.com/presentation/d/1XiQ-MaPiA656l1WwPaws4w4jFuKXD4TxIAvZ5rdlyJ4/edit?usp=sharing)

### 2019-06-24

@Amin and @António

2nd part

### 2019-06-17

@Amin and @António

Papers: TBD
